# `optim_adrs.py` â€” Optimisation linÃ©aire pour ADRS 1D (maillages fixes & adaptatifs)

Ce projet implÃ©mente lâ€™optimisation dâ€™une **ADRS 1D** (Advectionâ€“Diffusionâ€“RÃ©action avec Source) en exploitant la **linÃ©aritÃ©** de lâ€™Ã©quation dâ€™Ã©tat **par rapport aux contrÃ´les**.  
On compare deux pipelines :
- **RÃ©fÃ©rence** : maillage **uniforme fixe** (assez fin).  
- **Adaptatif** : chaque solution Ã©lÃ©mentaire est calculÃ©e sur **son maillage adaptÃ©**, puis **interpolÃ©e** vers une **grille commune** pour assembler les intÃ©grales.

---

## ğŸ”§ ProblÃ¨me

Sur \(x\in[0,1]\), on approche le stationnaire (par pseudo-temps explicite) de :
\[
u_t + V\,u_x - K\,u_{xx} + \lambda\,u \;=\; \sum_{i=1}^{N} x_i\,g_i(x),
\]
oÃ¹ \(x_i\) sont les **contrÃ´les** (poids des sources) et \(g_i\) des **gaussiennes** centrÃ©es \(c_i\).

**Fonctionnelle Ã  minimiser** :
\[
J(x) \;=\; \int_0^1 \big(u(x)-\text{Target}(x)\big)^2\,dx.
\]

---

## ğŸ§  LinÃ©aritÃ© â†’ base Ã©lÃ©mentaire \(\{T_i\}\)

En notant :
- \(T_0\) la solution pour contrÃ´le nul \(x=0\),
- \(T_i\) la solution pour le contrÃ´le unitÃ© \(e_i\) (1 sur i, 0 ailleurs),

on approxime (trÃ¨s bien dans ce cadre linÃ©aire) :
\[
u(x) \;\approx\; T_0 \;+\; \sum_{i=1}^N x_i\,T_i.
\]

Dâ€™oÃ¹ le **systÃ¨me normal de moindres carrÃ©s** :
\[
A_{ij} = \langle T_i, T_j \rangle,\qquad
B_i = \langle \text{Target}-T_0,\; T_i \rangle,\qquad
A\,x^\star = B.
\]

---

## ğŸ§© ProblÃ¨me pratique : maillages diffÃ©rents (adaptation)

Si chaque \(T_i\) est calculÃ© sur **son propre maillage adaptÃ©** \(x^{(i)}\), les produits
\(\langle T_i,T_j\rangle\) et \(\langle \text{Target}-T_0, T_i\rangle\) **ne sont pas** directement Ã©valuables.

**Solution** :  
1) Construire une **grille de rÃ©fÃ©rence commune** \(x^{\text{ref}}\) **suffisamment fine** (pas plus petit que les pas locaux / facteur de sÃ©curitÃ©).  
2) **InterpÃ´ler** toutes les fonctions \(T_i\), \(T_0\), \(\text{Target}\) vers \(x^{\text{ref}}\).  
3) Ã‰valuer les **intÃ©grales** avec une quadrature simple (trapÃ¨zes).  
4) **(Optionnel)** : ajouter un **test de Cauchy** sur la quadrature (raffiner \(x^{\text{ref}}\) jusquâ€™Ã  stabilisation Ã  \(10^{-8}\) par ex.), pour garantir que lâ€™erreur dâ€™intÃ©gration est **nÃ©gligeable** vis-Ã -vis de lâ€™erreur de modÃ¨le.

> RÃ¨gle pratique : la quadrature (grille commune) doit Ãªtre **bien plus fine** que les maillages des \(T_i\), de sorte que lâ€™erreur dâ€™intÃ©gration soit **1â€“2 ordres de grandeur** en dessous de lâ€™erreur finale tolÃ©rÃ©e (cf. poly de cours).

---

## ğŸ› ï¸ Ce que fait `optim_adrs.py`

- **RÃ©solution stationnaire** (pseudo-temps explicite, stabilisation advection par viscositÃ© numÃ©rique).  
- **RÃ©fÃ©rence fixe** : calcule \(T_0\), \(\text{Target}\), \(\{T_i\}\) sur **maillage uniforme fin**.  
- **Adaptatif** : pour chaque \(i\),  
  1) construit un **maillage adaptÃ©** (mÃ©trique \(\sqrt{|u_{xx}|}\) + Ã©quidistribution),  
  2) rÃ©sout \(T_i\) dessus,  
  3) **interpÃ´le** toutes les fonctions sur une **grille commune** pour assembler \(A,B\).  
- **RÃ©sout** \(A\,x=B\) â†’ obtient \(x^\star\) (fixe) et \(x^\star_{\text{adapt}}\) (adaptÃ©).  
- **Compare** les vecteurs optimaux, les reconstructions \(u_0 + \sum x_i T_i\) et lâ€™erreur \(L^2\) vs `Target`.  
- **Trace** la **surface \(J(x_1,x_2)\)** (les autres \(x_k\) figÃ©s Ã  lâ€™optimum fixe).

---

## â–¶ï¸ Utilisation

### PrÃ©requis
```bash
pip install numpy matplotlib
```

### Lancer
```bash
python optim_adrs.py
```

### ParamÃ¨tres utiles (en tÃªte du fichier)
- `N_ctrl` (nombre de contrÃ´les), `centers` (positions), `alpha` (largeur gaussienne),
- `NX_ref` (taille maillage uniforme de rÃ©fÃ©rence),
- `NX_adapt` (taille visÃ©e des maillages adaptÃ©s),
- `CFL`, `Tmax`, `eps_rel`, `NTmax` (intÃ©gration pseudo-temps),
- facteurs de construction de la **grille commune** (`refine_factor`, `NXmax`).

---

## ğŸ“ˆ Sorties / Figures

- **Carte \(J(x_1,x_2)\)** (contours), avec marqueurs des optima **fixe** vs **adaptÃ©**.  
- **Barres** des composantes du contrÃ´le optimal \(x^\star\) : **fixe** vs **adaptÃ©**.  
- **Comparaison** des reconstructions \(u^\star\) (fixe/adaptÃ©) Ã  la cible `Target`.  
- Log des **erreurs \(L^2\)** finales.

---

## âœ… Validation recommandÃ©e

1) **RafraÃ®chir la cible** : `Target` = solution associÃ©e Ã  un vecteur Â« vÃ©ritÃ© Â» `xcible` (fourni dans le code).  
2) **Monter** `NX_ref` jusquâ€™Ã  stabiliser \(\|u^\star - \text{Target}\|_{L^2}\) (critÃ¨re Cauchy).  
3) **Comparer** `xopt_fix` vs `xopt_adapt` :
   - Si la **grille commune** est assez fine et lâ€™**adaptation** bien posÃ©e, les deux doivent Ãªtre **proches** (differences mineures liÃ©es Ã  lâ€™interpolation et au pas de temps).  
4) **Tester** la sensibilitÃ© Ã  `refine_factor` (grille commune) pour garantir que lâ€™erreur dâ€™intÃ©gration est **nÃ©gligeable**.

---

## ğŸ“ Notes / Astuces

- **Stabilisation advection** : viscositÃ© numÃ©rique \(x_\nu = K + \tfrac{1}{2}|V|\,\Delta x\).  
- **CFL** conservateur : \(\Delta t \le \text{CFL}\cdot \min(\Delta x/|V|,\ \Delta x^2/(2K))\).  
- **Adaptation** : la mÃ©trique \(\sqrt{|u_{xx}|}\) concentre les nÅ“uds lÃ  oÃ¹ la solution est **courbe**.  
- **Quadrature** : si la **grille commune** est trop grossiÃ¨re, \(A\) et \(B\) sont **biaisÃ©s** â†’ optimum faux. Toujours vÃ©rifier la **stabilitÃ©** des intÃ©grales (test de Cauchy simple).

---

## ğŸ“Œ RÃ©sumÃ©

- On **exploite la linÃ©aritÃ©** en contrÃ´les : \(u \approx T_0+\sum x_iT_i\) et on rÃ©sout \(A\,x=B\).  
- Avec **maillages adaptÃ©s**, on **interpÃ´le** tout vers une **grille commune** fine pour **intÃ©grer** \(A_{ij}\), \(B_i\) sans biais.  
- On **compare** lâ€™optimum obtenu avec celui dâ€™un **maillage fixe de rÃ©fÃ©rence** (validation).  
- On **visualise** la **surface \(J(x_1,x_2)\)** et les **Ã©carts** entre solutions optimales.

